{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I. Setup",
   "id": "9c24b66f196a7efc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After implemented from scratch multiclass logistic regression and after tested it we can now do next steps to increase efficiency, effectiveness and upgrade this base model.",
   "id": "f8a9643052e719d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here it is abstract class of Logistic regression with empty fit function, we need to implement this fit function by yourself, because in next steps we will be adding there some upgrades and we need different class to compare it later",
   "id": "42ebd9296c49367d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n"
   ],
   "id": "b18a0e472c31bce8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Loading data\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()\n",
    "\n",
    "numerical_features = [\n",
    "    \"Application order\",\"Age at enrollment\", \"Curricular units 1st sem (credited)\", \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\"Curricular units 1st sem (approved)\",\"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\"Curricular units 2nd sem (credited)\",\"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\"Unemployment rate\",\"Inflation rate\",\"GDP\",\"Curricular units 2nd sem (grade)\"\n",
    "]\n",
    "categorical_features = [\n",
    "    \"Marital status\",\"Application mode\",\"Course\",\"Daytime/evening attendance\",\"Previous qualification\",\"Nationality\",\n",
    "    \"Mother's qualification\",\"Father's qualification\",\"Mother's occupation\",\"Father's occupation\",\"Displaced\",\n",
    "    \"Educational special needs\",\"Debtor\",\"Tuition fees up to date\",\"Gender\",\"Scholarship holder\",\"International\"\n",
    "]\n",
    "\n",
    "target = \"Target\"\n",
    "\n",
    "preprocessor_full_set = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore',sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "def transform_in_pipeline(preproc,X_ttrain,X_ttest,y_ttrain,y_ttest):\n",
    "    return  (preproc.fit_transform(X_ttrain), preproc.transform(X_ttest),\n",
    "             pd.get_dummies(y_ttrain,columns=[\"Target\"]).astype(int).to_numpy(), pd.get_dummies(y_ttest,columns=[\"Target\"]).astype(int).to_numpy())\n"
   ],
   "id": "2998b9f60438c5cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# HERE Y has to be in onehotencoder [0 0 ...  1]\n",
    "X = df.drop([\"Target\"], axis=1)\n",
    "y = df[\"Target\"]\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)\n"
   ],
   "id": "2c6d179542de2ed6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class LogisticRegression(ABC):\n",
    "    def __init__(self, lr=0.001, n_iters=5000, batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.batch_idx = 0\n",
    "        self.n_iters = n_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.errors = []\n",
    "        self.n_classes = None\n",
    "        self.probabilities = None\n",
    "    def error_function(self, y, predicted, m_samples):\n",
    "        return -np.sum(y * np.log(predicted + 1e-15)) / m_samples\n",
    "\n",
    "    def softmax(self,z):\n",
    "        return np.exp(z)/np.sum(np.exp(z),axis=1,keepdims=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        return self.softmax(z)\n",
    "\n",
    "    def predict_class(self, X_test):\n",
    "        probabilities = self.predict(X_test)\n",
    "        self.probabilities = probabilities\n",
    "        return np.argmax(probabilities, axis=1).reshape(-1, 1)\n",
    "\n",
    "    def score(self, predicted, y):\n",
    "        y_true = np.argmax(y, axis=1)\n",
    "        correct = (predicted.flatten() == y_true)\n",
    "        accuracy = np.mean(correct)\n",
    "        return accuracy\n",
    "\n",
    "    def raw_error_data(self):\n",
    "        return np.arange(len(self.errors)), self.errors\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "       ..."
   ],
   "id": "15d0c9d4380ea00b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we start with base multiclass logistic regression without any specific upgrades",
   "id": "f2357cf1d80c59e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BaseLogisticRegression(LogisticRegression):\n",
    "    def fit(self,X,y):\n",
    "        m_samples, n_features = X.shape\n",
    "        self.n_classes = y.shape[1]\n",
    "        self.weights = np.zeros((n_features, self.n_classes))\n",
    "        self.bias = np.zeros((1, self.n_classes))\n",
    "        self.errors.clear()\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            indices = np.random.permutation(m_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for start_idx in range(0, m_samples, self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_shuffled[start_idx:end_idx]\n",
    "                y_batch = y_shuffled[start_idx:end_idx]\n",
    "\n",
    "                predict = self.predict(X_batch)\n",
    "                dw = (1 / X_batch.shape[0]) * np.dot(X_batch.T, (predict - y_batch))\n",
    "                db = (1 / X_batch.shape[0]) * np.sum(predict - y_batch, axis=0, keepdims=True)\n",
    "\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "\n",
    "            full_predict = self.predict(X)\n",
    "            loss = self.error_function(y, full_predict, m_samples)\n",
    "            self.errors.append(loss)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "\n"
   ],
   "id": "9ce758dbc9c6b97f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can train and predict results on these subsets, which were made with random_state=$42$",
   "id": "c3ded0e5c97c9396"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_proc,X_test_proc,y_train_proc,y_test_proc = transform_in_pipeline(preprocessor_full_set,X_train, X_test, y_train, y_test)\n",
    "\n",
    "logistic_regression1 = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)"
   ],
   "id": "4d6cc1f7fe791b65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression1.fit(X_train_proc, y_train_proc)\n",
    "predicted = logistic_regression1.predict_class(X_test_proc)\n",
    "\n",
    "logistic_regression1.score(predicted, y_test_proc)"
   ],
   "id": "a341ca1843e6e7ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "But now we can change this random_state variable to show that is random to generate a subsets,and based on this random we can get bad or worse score",
   "id": "987be98625793d9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(X,y,train_size=0.7,random_state=11)\n",
    "X_train_proc2,X_test_proc2,y_train_proc2,y_test_proc2 = transform_in_pipeline(preprocessor_full_set,X_train2, X_test2, y_train2, y_test2)\n",
    "\n",
    "logistic_regression2 = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n"
   ],
   "id": "b5aa6c501825c4b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression2.fit(X_train_proc2, y_train_proc2)\n",
    "predicted2 = logistic_regression2.predict_class(X_test_proc2)\n",
    "logistic_regression2.score(predicted2, y_test_proc2)"
   ],
   "id": "5bf000f7cddd6189",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\\begin{align*}\n",
    "\\text{accuracy}(\\text{random\\_state} = 42) &= 0.7665 \\\\\n",
    "\\text{accuracy}(\\text{random\\_state} = 11) &= 0.7710\n",
    "\\end{align*}\n",
    "\n",
    "And we can see that is real random, so we have to find way to do this more independent of random_state\n"
   ],
   "id": "3365c359ef789587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "II. Cross validation (StratifiedKFold)",
   "id": "dc26628d7a654471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def make_cross_validation_predict(model,preproc, X_set, y_set, k=3):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(k, shuffle=True)\n",
    "\n",
    "    y_encoded = LabelEncoder().fit_transform(y_set)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_set, y_encoded):\n",
    "        X_train_raw = X_set.iloc[train_index]\n",
    "        X_test_raw = X_set.iloc[test_index]\n",
    "\n",
    "        y_train_raw = y_set.iloc[train_index]\n",
    "        y_test_raw = y_set.iloc[test_index]\n",
    "\n",
    "        X_train = preproc.fit_transform(X_train_raw)\n",
    "        X_test = preproc.transform(X_test_raw)\n",
    "\n",
    "        y_train = pd.get_dummies(y_train_raw).astype(int).to_numpy()\n",
    "        y_test = pd.get_dummies(y_test_raw).astype(int).to_numpy()\n",
    "        model.fit(X_train, y_train)\n",
    "        predicted = model.predict_class(X_test)\n",
    "        score = model.score(predicted, y_test)\n",
    "        scores.append(score)\n",
    "\n",
    "\n",
    "    return scores, np.mean(scores)\n"
   ],
   "id": "717707594501e66f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression3 = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "\n",
    "make_cross_validation_predict(logistic_regression3, preprocessor_full_set, X_train, y_train)"
   ],
   "id": "b1ba76db41058af0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And now we can see this what we saw before, that in every run, we get different prediction. So for this reason using cross-validation is is important therefore in next step of upgrades we will be using this method.\n",
   "id": "c708e36bcfc9da8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "II. Over/under-fitting and error plot",
   "id": "eb9c179fc98035a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we have to search if we have either overfitting or underfitting using our base logistic regression model.",
   "id": "1015a11e19398fd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_CV_logistic_regression = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "make_cross_validation_predict(base_CV_logistic_regression, preprocessor_full_set, X_train, y_train)"
   ],
   "id": "fe04ee83aae72656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_logistic_regression = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)",
   "id": "dd711648b667e1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#train base_logistic_regression\n",
    "base_logistic_regression.fit(X_train_proc,y_train_proc)"
   ],
   "id": "29a1d05c76da69e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = base_logistic_regression.predict_class(X_train_proc)\n",
    "print(base_logistic_regression.score(predicted, y_train_proc))\n",
    "x1,y1 = base_logistic_regression.raw_error_data()\n"
   ],
   "id": "6d668fcedb357bc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = base_logistic_regression.predict_class(X_test_proc)\n",
    "print(base_logistic_regression.score(predicted, y_test_proc))\n",
    "x2,y2 = base_logistic_regression.raw_error_data()"
   ],
   "id": "f2f1cdca053df48e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(x1, y1, label=\"Train set\", color='blue', linestyle='-')\n",
    "plt.plot(x2, y2, label=\"Test set\", color='orange', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "ce668da263984e75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Based on this plot we can say that our lines are close to each other, so we don't have problem with under or over-fitting\n",
    "\n",
    "And also we have scores:\n",
    "\\begin{align*}\n",
    "\\text{accuracy}(\\text{CV}) &= 0.7719 \\\\\n",
    "\\text{accuracy}(\\text{on train}) &= 0.8016 \\\\\n",
    "\\text{accuracy}(\\text{on test}) &= 0.7665\n",
    "\\end{align*}\n",
    "We can see that $Test~\\approx~CV~\\approx~Train$ so it means that we don't have problem with underfitting or overfitting"
   ],
   "id": "98386976865dc571"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Although we don't have problem with under/over - fitting still we can try to improve model with PolynomialFeatures\n",
   "id": "b067d0b51f296300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_pipeline_poly = Pipeline([\n",
    "    ('poly',PolynomialFeatures(degree=2,include_bias=False)),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n",
    "polynomial_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline_poly, numerical_features),\n",
    "        ('cat',OneHotEncoder(handle_unknown='ignore',sparse_output=False),categorical_features)\n",
    "    ]\n",
    ")\n"
   ],
   "id": "c98ee8f8ba69b7e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "polynomial_CV_logistic_regression = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "make_cross_validation_predict(polynomial_CV_logistic_regression, polynomial_preprocessor, X_train, y_train)"
   ],
   "id": "a39c4629e8d0a803",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_proc_poly,X_test_proc_poly,y_train_proc_poly,y_test_proc_poly = transform_in_pipeline(polynomial_preprocessor,X_train, X_test, y_train, y_test)",
   "id": "e71b30ff90204ff6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "polynomial_base_logistic_regression = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "polynomial_base_logistic_regression.fit(X_train_proc_poly,y_train_proc_poly)"
   ],
   "id": "93a047095c5d2115",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = polynomial_base_logistic_regression.predict_class(X_train_proc_poly)\n",
    "print(polynomial_base_logistic_regression.score(predicted, y_train_proc_poly))"
   ],
   "id": "239db0dfe44d03fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted = polynomial_base_logistic_regression.predict_class(X_test_proc_poly)\n",
    "print(polynomial_base_logistic_regression.score(predicted, y_test_proc_poly))"
   ],
   "id": "81cf5c1eb2b43d53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And we can see that we get little better scores using this modified preprocessor.",
   "id": "81dfeb6626b3b264"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we can ask question, do we need all of the columns in training our model, maybe we can delete some of them and our score won't be worse",
   "id": "d8306be74b724638"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_features_modified = [\n",
    "    \"Application order\",\"Age at enrollment\", \"Curricular units 1st sem (credited)\", \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\"Curricular units 1st sem (approved)\",\"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\"Curricular units 2nd sem (credited)\",\"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\"Curricular units 2nd sem (grade)\"\n",
    "]\n",
    "categorical_features_modified = [\n",
    "    \"Marital status\",\"Application mode\",\"Course\",\"Daytime/evening attendance\",\"Previous qualification\",\n",
    "    \"Mother's qualification\",\"Father's qualification\",\"Mother's occupation\",\"Father's occupation\",\"Displaced\",\n",
    "    \"Educational special needs\",\"Debtor\",\"Tuition fees up to date\",\"Gender\",\"Scholarship holder\"\n",
    "]\n",
    "\n",
    "\n",
    "df_modified = pd.read_csv(\"dataset.csv\")\n",
    "#pipeline"
   ],
   "id": "125393cdadf93117",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y = df_modified[\"Target\"]\n",
    "X = df_modified[numerical_features_modified+categorical_features_modified]"
   ],
   "id": "5648b8ee5e02e3f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_pipeline_modified_features = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "modified_features_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline_modified_features, numerical_features_modified),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_modified)\n",
    "    ]\n",
    ")\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ],
   "id": "3fdeae8f87f70ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "modified_features_CV_logistic_regression = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "print(make_cross_validation_predict(modified_features_CV_logistic_regression, modified_features_preprocessor, X_train, y_train))\n",
    "print(modified_features_CV_logistic_regression.weights)"
   ],
   "id": "aca99bb7d1ed264c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "hAfter few tries we got new sets of features, which is smaller that entry features set, and now score after CV is slightly better.",
   "id": "b130519f3688db3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Moving to the next steps, we are going with:\n",
    "\n",
    "- smaller dataset\n",
    "- `modified_features_preprocessor` preprocessor with `PolynomialFeatures`\n",
    "- `X_train`, `X_test`, `y_train`, `y_test`\n"
   ],
   "id": "397e45fc42d2136"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "III. L1, L2 regularization\n",
    "importance of the input\n",
    "\n",
    "Regularization method are applied to regression model because we want to have more control on weights in our model, because weights are responsible for features importance in\n",
    "training model. So we can use regularization techniques to work on these  weights. We to penalize model for to high weights.\n",
    "\n",
    "- `L1 (lasso)`\n",
    "$\\lambda \\sum_{i,j} |W_{ij}|$\n",
    "\n",
    "This method are going to even make some features zero by zero weight to eliminate unnecessary feautres\n",
    "- `L2 (ridge)`\n",
    "$\\lambda \\sum_{i,j} W_{ij}^2$\n",
    "\n",
    "This method are going to penalize model more significant because of square"
   ],
   "id": "16cf4e852321f817"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#X_train_proc,X_test_proc,y_train_proc,y_test_proc = transform_in_pipeline(polynomial_preprocessor,X_train, X_test, y_train, y_test)",
   "id": "70aa65765ac642de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BaseLogisticRegressionRegL1(LogisticRegression):\n",
    "    def __init__(self,n_iters=5000, lr=0.001, batch_size=64,l=0.001):\n",
    "        super().__init__(lr, n_iters, batch_size)\n",
    "        self.l = l\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        m_samples, n_features = X.shape\n",
    "        self.n_classes = y.shape[1]\n",
    "        self.weights = np.zeros((n_features, self.n_classes))\n",
    "        self.bias = np.zeros((1, self.n_classes))\n",
    "        self.errors.clear()\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            indices = np.random.permutation(m_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for start_idx in range(0, m_samples, self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_shuffled[start_idx:end_idx]\n",
    "                y_batch = y_shuffled[start_idx:end_idx]\n",
    "\n",
    "                predict = self.predict(X_batch)\n",
    "                dw = (1 / X_batch.shape[0]) * np.dot(X_batch.T, (predict - y_batch))\n",
    "\n",
    "                dw+=self.l * np.sign(self.weights)\n",
    "\n",
    "                db = (1 / X_batch.shape[0]) * np.sum(predict - y_batch, axis=0, keepdims=True)\n",
    "\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "\n",
    "            full_predict = self.predict(X)\n",
    "            loss = self.error_function(y, full_predict, m_samples)\n",
    "            self.errors.append(loss)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n"
   ],
   "id": "7e0d234db830e04e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BaseLogisticRegressionRegL2(LogisticRegression):\n",
    "    def __init__(self,n_iters=5000, lr=0.001, batch_size=64,l=0.001):\n",
    "        super().__init__(lr, n_iters, batch_size)\n",
    "        self.l = l\n",
    "    def fit(self,X,y):\n",
    "        m_samples, n_features = X.shape\n",
    "        self.n_classes = y.shape[1]\n",
    "        self.weights = np.zeros((n_features, self.n_classes))\n",
    "        self.bias = np.zeros((1, self.n_classes))\n",
    "        self.errors.clear()\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            indices = np.random.permutation(m_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for start_idx in range(0, m_samples, self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_shuffled[start_idx:end_idx]\n",
    "                y_batch = y_shuffled[start_idx:end_idx]\n",
    "\n",
    "                predict = self.predict(X_batch)\n",
    "                dw = (1 / X_batch.shape[0]) * np.dot(X_batch.T, (predict - y_batch))\n",
    "\n",
    "                dw += self.l * 2 * self.weights\n",
    "\n",
    "                db = (1 / X_batch.shape[0]) * np.sum(predict - y_batch, axis=0, keepdims=True)\n",
    "\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "\n",
    "            full_predict = self.predict(X)\n",
    "            loss = self.error_function(y, full_predict, m_samples)\n",
    "            self.errors.append(loss)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n"
   ],
   "id": "1dda45975b476039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_L1_reg = BaseLogisticRegressionRegL1(n_iters=5000, lr=0.001, batch_size=64,l=0.001)\n",
    "print(make_cross_validation_predict(logistic_regression_L1_reg, modified_features_preprocessor, X_train, y_train))\n",
    "print(logistic_regression_L1_reg.weights)"
   ],
   "id": "2f5e426eb3651a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_L2_reg = BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64,l=0.001)\n",
    "print(make_cross_validation_predict(logistic_regression_L2_reg, modified_features_preprocessor, X_train, y_train))\n",
    "print(logistic_regression_L2_reg.weights)\n"
   ],
   "id": "dcaaf6aafdf76b3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "12e09ed5a64648c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class BaseLogisticRegressionRegCombined(LogisticRegression):\n",
    "    def __init__(self,n_iters=5000, lr=0.001, batch_size=64,l=0.001,alpha=0.7):\n",
    "        super().__init__(lr, n_iters, batch_size)\n",
    "        self.l = l\n",
    "        self.alpha = alpha\n",
    "    def fit(self,X,y):\n",
    "        m_samples, n_features = X.shape\n",
    "        self.n_classes = y.shape[1]\n",
    "        self.weights = np.zeros((n_features, self.n_classes))\n",
    "        self.bias = np.zeros((1, self.n_classes))\n",
    "        self.errors.clear()\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            indices = np.random.permutation(m_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for start_idx in range(0, m_samples, self.batch_size):\n",
    "                end_idx = start_idx + self.batch_size\n",
    "                X_batch = X_shuffled[start_idx:end_idx]\n",
    "                y_batch = y_shuffled[start_idx:end_idx]\n",
    "\n",
    "                predict = self.predict(X_batch)\n",
    "                l2_gradient = self.l * (1 - self.alpha) * 2 * self.weights\n",
    "                l1_gradient = self.l * self.alpha * np.sign(self.weights)\n",
    "                dw = (1 / X_batch.shape[0]) * np.dot(X_batch.T, (predict - y_batch))\n",
    "                dw += l1_gradient+l2_gradient\n",
    "                db = (1 / X_batch.shape[0]) * np.sum(predict - y_batch, axis=0, keepdims=True)\n",
    "\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "\n",
    "            full_predict = self.predict(X)\n",
    "            loss = self.error_function(y, full_predict, m_samples)\n",
    "            self.errors.append(loss)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration {i}, Loss: {loss:.4f}\")\n",
    "\n"
   ],
   "id": "88db976382c63027",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_L1L2 = BaseLogisticRegressionRegCombined(n_iters=5000, lr=0.001, batch_size=128,l=0.001,alpha=0.50)\n",
    "print(make_cross_validation_predict(logistic_regression_L1L2, modified_features_preprocessor, X_train, y_train))"
   ],
   "id": "5acd04aec94657b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#weights before L1\n",
    "plt.hist((modified_features_CV_logistic_regression.weights).flatten(), bins=100)\n",
    "plt.xlabel(\"Absolute weight value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of absolute weights\")\n",
    "plt.show()"
   ],
   "id": "bacb67f1f979ad6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#weights after L1\n",
    "plt.hist(logistic_regression_L1_reg.weights.flatten(), bins=100)\n",
    "plt.xlabel(\"Absolute weight value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of absolute weights\")\n",
    "plt.show()"
   ],
   "id": "bbc235edff39a000",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "We can also see that mean accuracy before and after implemented L1 and L2 are very similar, thus can confirm that our model is not overfitted."
   ],
   "id": "7847b5ed3b123a26"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "IV. Dataset balancing\n",
    "\n",
    "Dataset balancing is crucial in model training because when we are training our data on some part of full dataset it can be possible that occurrence one class can be much bigger than others, so after training model on unbalanced dataset model can simply always guess this class which occurrence were the biggest in training set. It is oversampling, we have similar situation with undersampling when it's the other way around."
   ],
   "id": "bc49ab18fba2ad40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "d_set = numerical_features_modified+categorical_features_modified\n",
    "\n",
    "def sampling_method_pipeline(X_ttrain, y_ttrain, method):\n",
    "    X_ttrain = X_ttrain.copy()\n",
    "    y_ttrain = y_ttrain.copy()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_ttrain = le.fit_transform(y_ttrain.values.ravel() if isinstance(y_ttrain, pd.DataFrame) else y_ttrain)\n",
    "    resampler = None\n",
    "    match method:\n",
    "        case \"SMOTE\":\n",
    "            resampler = SMOTENC(\n",
    "            categorical_features=categorical_features_modified,\n",
    "            random_state=42\n",
    "            )\n",
    "        case \"RandomUnderSampler\":\n",
    "            resampler = RandomUnderSampler(random_state=42)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    X_resampled, y_resampled = resampler.fit_resample(X_ttrain, y_ttrain)\n",
    "\n",
    "    return X_resampled, y_resampled\n"
   ],
   "id": "43a58635fbe8c058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_cross_validation_predict_sampling(model, preproc, X_set, y_set, sampling_method=None, k=3):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    y_encoded = LabelEncoder().fit_transform(y_set)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_set, y_encoded):\n",
    "        X_train_raw = X_set.iloc[train_index]\n",
    "        X_test_raw = X_set.iloc[test_index]\n",
    "\n",
    "        y_train_raw = y_set.iloc[train_index]\n",
    "        y_test_raw = y_set.iloc[test_index]\n",
    "\n",
    "        if sampling_method is not None:\n",
    "            X_train_resampled, y_train_resampled = sampling_method_pipeline(pd.DataFrame(X_train_raw), y_train_raw, sampling_method)\n",
    "            X_train = X_train_resampled\n",
    "            y_train = y_train_resampled\n",
    "        else:\n",
    "            X_train = X_train_raw\n",
    "            y_train = y_train_raw.values.ravel()\n",
    "\n",
    "        X_train = preproc.fit_transform(X_train)\n",
    "        X_test = preproc.transform(X_test_raw)\n",
    "\n",
    "        y_test_encoded = pd.get_dummies(y_test_raw).astype(int).to_numpy()\n",
    "        y_train_encoded = pd.get_dummies(y_train).astype(int).to_numpy()\n",
    "\n",
    "        model.fit(X_train, y_train_encoded)\n",
    "\n",
    "        predicted = model.predict_class(X_test)\n",
    "        score = model.score(predicted, y_test_encoded)\n",
    "        scores.append(score)\n",
    "        y_encoded_t =np.argmax(y_test_encoded,axis=1)\n",
    "        print(classification_report(y_encoded_t, predicted, digits=4))\n",
    "\n",
    "    return scores, np.mean(scores)\n",
    "\n"
   ],
   "id": "63c915de7fe5a80b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logistic_regression_L2 = BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64,l=0.001)\n",
    "print(make_cross_validation_predict_sampling(logistic_regression_L2, modified_features_preprocessor, X_train, y_train,sampling_method=\"RandomUnderSampler\"))"
   ],
   "id": "68501e9d2cee1deb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.metrics import classification_report",
   "id": "13c16d525e4f682b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_proc, X_test_proc, y_train_proc, y_test_proc = transform_in_pipeline(modified_features_preprocessor, X_train, X_test,y_train,y_test)\n",
    "log_reg = BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64)\n",
    "log_reg.fit(X_train_proc, y_train_proc)\n",
    "predicted = log_reg.predict_class(X_test_proc)\n",
    "\n"
   ],
   "id": "d91fb96837bbebc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_test_proc = np.argmax(y_test_proc,axis=1) if y_test_proc.ndim>1 else y_test_proc\n",
    "print(classification_report(y_test_proc, predicted, digits=4))\n"
   ],
   "id": "26933b7a2004d841",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_res_train,y_res_train = sampling_method_pipeline(X_train,y_train,method=\"SMOTE\")\n",
    "X_train_proc, X_test_proc, y_train_proc, y_test_proc = transform_in_pipeline(modified_features_preprocessor, X_res_train, X_test,y_res_train,y_test)\n",
    "log_reg = BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64)\n",
    "log_reg.fit(X_train_proc, y_train_proc)\n",
    "predicted = log_reg.predict_class(X_test_proc)\n"
   ],
   "id": "3d0f94765e4c1f7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_test_proc = np.argmax(y_test_proc,axis=1) if y_test_proc.ndim>1 else y_test_proc\n",
    "print(classification_report(y_test_proc, predicted, digits=4))\n"
   ],
   "id": "86532d5685941318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_res_train,y_res_train = sampling_method_pipeline(X_train,y_train,method=\"RandomUnderSampler\")",
   "id": "48444a9119cdbaf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_proc, X_test_proc, y_train_proc, y_test_proc = transform_in_pipeline(modified_features_preprocessor, X_res_train, X_test,y_res_train,y_test)\n",
    "log_reg = BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64)\n",
    "log_reg.fit(X_train_proc, y_train_proc)\n",
    "predicted = log_reg.predict_class(X_test_proc)\n",
    "\n"
   ],
   "id": "688b679ec117b920",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_test_proc = np.argmax(y_test_proc,axis=1) if y_test_proc.ndim>1 else y_test_proc\n",
    "print(classification_report(y_test_proc, predicted, digits=4))\n"
   ],
   "id": "a441156c8f5c0e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So here me made three runs of regression model to show differences between dataset without sampling and with sampling.\n",
    "- I scores\n",
    "We can see that this model ignores 1 class and favors 2 class, so we can assume that this is unbalanced dataset, because of better model correctness of dominated class, than minor class\n",
    "- II scores (after balanced)\n",
    "We can see that here was used some balanced techniques because of better balance between recall factor for all three classes\n",
    "- III scores (after balanced)\n",
    "This scores looks the best from this three because the recall value for all of them is high and similar to each other, so we don't have situation that model favours one of classes"
   ],
   "id": "452111189440d95e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "V. Optimizing hiperparmeters",
   "id": "8481a4d875989d2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Out models have a variables that is constant during training our model so we have to be sure that our set values are good enough. To be sure we can optimizing it in `GridSearchCV`\n",
    "We are working of logistic regression variances so we will optimize these parameters:\n",
    "- `BaseLogisticRegresion` - `n_iter`  |  `lr`  |  `batch_size`\n",
    "- `BaseLogisticRegressionRegCombined` - `n_iter`  |  `lr`  |  `batch_size` | `l` |`alpha`"
   ],
   "id": "21e0640dd4799e82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "# BASE LOGISTIC REGRESSION\n",
    "param_grid = {\n",
    "    \"n_iters\":[3000,4000,5000,6000,7000,8000,9000,10000],\n",
    "    \"lr\":[0.001,0.0001,0.00001],\n",
    "    \"batch_size\":[32,64,128]\n",
    "}\n",
    "best = -1\n",
    "best_params = None\n",
    "keys = list(param_grid.keys())\n",
    "combinations = list(product(*param_grid.values()))\n",
    "for combo in combinations:\n",
    "    params = dict(zip(keys,combo))\n",
    "    model = BaseLogisticRegression(**params)\n",
    "    mean = make_cross_validation_predict(model,\n",
    "                                           modified_features_preprocessor,\n",
    "                                           X_train, y_train,\n",
    "                                           k=2)[1]\n",
    "    if mean > best:\n",
    "        best = mean\n",
    "        best_params = params\n",
    "print(best_params,best)"
   ],
   "id": "2d57fb700511158d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "# BASE LOGISTIC REGRESSION WITH L1 L2\n",
    "param_grid = {\n",
    "    \"n_iters\":[4000,5000,6000],\n",
    "    \"lr\":[0.001,0.0001,0.00001],\n",
    "    \"batch_size\":[64,128],\n",
    "    \"l\" :[0.001,0.0001,0.00001],\n",
    "    \"alpha\" :[0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "}\n",
    "best = -1\n",
    "best_params = None\n",
    "keys = list(param_grid.keys())\n",
    "combinations = list(product(*param_grid.values()))\n",
    "for i,combo in enumerate(combinations):\n",
    "    print(i, len(combinations))\n",
    "    params = dict(zip(keys,combo))\n",
    "    model = BaseLogisticRegressionRegCombined(**params)\n",
    "    mean = make_cross_validation_predict(model,\n",
    "                                           modified_features_preprocessor,\n",
    "                                           X_train, y_train,\n",
    "                                           k=2)[1]\n",
    "    if mean > best:\n",
    "        best = mean\n",
    "        best_params = params\n",
    "print(best_params,best)"
   ],
   "id": "1793525944fd30e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "# BASE LOGISTIC REGRESSION WITH L1 L2\n",
    "param_grid = {\n",
    "    \"n_iters\":[4000,5000,6000],\n",
    "    \"lr\":[0.001,0.0001,0.00001],\n",
    "    \"batch_size\":[64,128],\n",
    "    \"l\" :[0.001,0.0001,0.00001],\n",
    "}\n",
    "best = -1\n",
    "best_params = None\n",
    "keys = list(param_grid.keys())\n",
    "combinations = list(product(*param_grid.values()))\n",
    "for i,combo in enumerate(combinations):\n",
    "    print(i, len(combinations))\n",
    "    params = dict(zip(keys,combo))\n",
    "    model = BaseLogisticRegressionRegL2(**params)\n",
    "    mean = make_cross_validation_predict(model,\n",
    "                                           modified_features_preprocessor,\n",
    "                                           X_train, y_train,\n",
    "                                           k=2)[1]\n",
    "    if mean > best:\n",
    "        best = mean\n",
    "        best_params = params\n",
    "print(best_params,best)"
   ],
   "id": "5bf1e11f417b35a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "WVI. Ensemble methods",
   "id": "ea57a47460bfe351"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "X_train_proc1, X_test_proc1, y_train_proc1, y_test_proc1 = transform_in_pipeline(\n",
    "    modified_features_preprocessor, X_train, X_test, y_train, y_test)\n",
    "\n",
    "X_train_proc2, X_test_proc2, y_train_proc2, y_test_proc2 = transform_in_pipeline(\n",
    "    preprocessor_full_set, X_train, X_test, y_train, y_test)\n",
    "base = BaseLogisticRegression(n_iters=5000, lr=0.001, batch_size=64)\n",
    "base_L1 = BaseLogisticRegressionRegL1(n_iters=5000, lr=0.001, batch_size=64, l=0.001)\n",
    "base_L2 =BaseLogisticRegressionRegL2(n_iters=5000, lr=0.001, batch_size=64, l=0.001)\n",
    "base_L1L2 = BaseLogisticRegressionRegCombined(n_iters=5000, lr=0.001, batch_size=64, l=0.00101, alpha=0.70)\n",
    "models_list = [\n",
    "    (base, \"base\",1),\n",
    "    (base_L1, \"base+L1\",1),\n",
    "    (base_L2, \"base+L2\",2),\n",
    "    (base_L1L2, \"base+L1L2\",2)\n",
    "]\n",
    "\n",
    "trained_models = []\n",
    "for model, name,num in models_list:\n",
    "    if num==1:\n",
    "        model.fit(X_train_proc1,y_train_proc1)\n",
    "    if num==2:\n",
    "        model.fit(X_train_proc2,y_train_proc2)\n",
    "    trained_models.append((model, name,num))\n",
    "\n",
    "predictions = {}\n",
    "errors = {}\n",
    "\n",
    "for model, name,num in trained_models:\n",
    "    if num==1:\n",
    "        y_pred = model.predict_class(X_test_proc1)\n",
    "        predictions[name] = y_pred\n",
    "        y_true = np.argmax(y_test_proc1, axis=1) if y_test_proc1.ndim > 1 else y_test_proc1\n",
    "        errors[name] = (y_pred.flatten() != y_true).astype(int)\n",
    "    if num==2:\n",
    "        y_pred = model.predict_class(X_test_proc2)\n",
    "        predictions[name] = y_pred\n",
    "        y_true = np.argmax(y_test_proc2, axis=1) if y_test_proc2.ndim > 1 else y_test_proc2\n",
    "        errors[name] = (y_pred.flatten() != y_true).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "errors_df = pd.DataFrame(errors)\n",
    "\n",
    "error_correlation = errors_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(error_correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Macierz korelacji błędów między modelami')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e171bffcfe15954a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see on this matrix that base model and base_L1L2 model has the lowest correlation score so they are better in different records (but still this is high correlation score)\n",
    "\n",
    "Ensemble methods:\n",
    "- HardVotingClassifier\n",
    "Here we have n classifiers and every of that returning their prediction for every record, HardVotingClassifier choose the most frequent label  and this is final prediction\n",
    "\n",
    "- StackingClassifier"
   ],
   "id": "ff9a19174ea18922"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = [\n",
    "    BaseLogisticRegression(n_iters=7000, lr=0.001, batch_size=64),\n",
    "    BaseLogisticRegressionRegCombined(n_iters=4000, lr=0.001, batch_size=128, l=0.0010, alpha=0.50)\n",
    "    ]\n",
    "def HardVotingClassifier(models,X_train,y_train,X_test,y_test):\n",
    "    models[0].fit(X_train,y_train)\n",
    "    models[1].fit(X_train,y_train)\n",
    "    y_pred_1 = models[0].predict_class(X_test)\n",
    "    y_pred_2 = models[1].predict_class(X_test)\n",
    "    pred = []\n",
    "    for row1,row2 in zip(y_pred_1,y_pred_2):\n",
    "        d ={0:0,1:0,2:0}\n",
    "        for elem in row1:\n",
    "            d[elem]+=1\n",
    "        for elem in row2:\n",
    "            d[elem]+=1\n",
    "        pred.append(max(d, key=d.get))\n",
    "\n",
    "    return pred"
   ],
   "id": "85af3fc03103620c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred = HardVotingClassifier(models,X_train_proc1,y_train_proc1,X_test_proc1,y_test_proc1)\n",
    "p = np.array(pred)\n",
    "def score(predicted, y):\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    correct = (predicted.flatten() == y_true)\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "score(p,y_test_proc1)"
   ],
   "id": "308b9159b7bc0e07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_cross_validation_predict_voting(models, preproc, X_set, y_set, k=3):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    y_encoded = LabelEncoder().fit_transform(y_set)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_set, y_encoded):\n",
    "        X_train_raw = X_set.iloc[train_index]\n",
    "        X_test_raw = X_set.iloc[test_index]\n",
    "\n",
    "        y_train_raw = y_set.iloc[train_index]\n",
    "        y_test_raw = y_set.iloc[test_index]\n",
    "\n",
    "        X_train = preproc.fit_transform(X_train_raw)\n",
    "        X_test = preproc.transform(X_test_raw)\n",
    "\n",
    "        y_train = pd.get_dummies(y_train_raw).astype(int).to_numpy()\n",
    "        y_test = pd.get_dummies(y_test_raw).astype(int).to_numpy()\n",
    "\n",
    "        models[0].fit(X_train, y_train)\n",
    "        models[1].fit(X_train, y_train)\n",
    "\n",
    "        y_pred_1 = models[0].predict_class(X_test)\n",
    "        y_pred_2 = models[1].predict_class(X_test)\n",
    "\n",
    "        # Hard voting\n",
    "        pred = []\n",
    "        for row1, row2 in zip(y_pred_1, y_pred_2):\n",
    "            d = {0: 0, 1: 0, 2: 0}\n",
    "            for elem in row1:\n",
    "                d[elem] += 1\n",
    "            for elem in row2:\n",
    "                d[elem] += 1\n",
    "            pred.append(max(d, key=d.get))\n",
    "\n",
    "        pred = np.array(pred)\n",
    "\n",
    "        fold_score = score(pred, y_test)\n",
    "        scores.append(fold_score)\n",
    "\n",
    "    return scores, np.mean(scores)\n",
    "\n",
    "def score(predicted, y):\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    correct = (predicted.flatten() == y_true)\n",
    "    return np.mean(correct)\n",
    "print(make_cross_validation_predict_voting(models, modified_features_preprocessor, X_train, y_train))"
   ],
   "id": "124bc7063feeccc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = [\n",
    "    BaseLogisticRegression(n_iters=7000, lr=0.001, batch_size=64),\n",
    "    BaseLogisticRegressionRegCombined(n_iters=4000, lr=0.001, batch_size=128, l=0.0010, alpha=0.50)\n",
    "    ]\n",
    "def StackingClassifier(models,X_train,y_train,X_test,y_test):\n",
    "    models[0].fit(X_train,y_train)\n",
    "    models[1].fit(X_train,y_train)\n",
    "    models[0].predict_class(X_test)\n",
    "    models[1].predict_class(X_test)\n",
    "    prob1 = models[0].probabilities\n",
    "    prob2 = models[1].probabilities\n",
    "    results = []\n",
    "    for row1,row2 in zip(prob1,prob2):\n",
    "        c = np.hstack((row1,row2))\n",
    "        results.append(c)\n",
    "    return np.array(results)"
   ],
   "id": "82265da8ebf2ae08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred = StackingClassifier(models,X_train_proc1,y_train_proc1,X_test_proc1,y_test_proc1)\n",
    "pred"
   ],
   "id": "c37a1d8373fe5367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y =y_test_proc1.copy()\n",
    "model = BaseLogisticRegressionRegCombined(n_iters=4000, lr=0.001,batch_size=128,l=0.001, alpha=0.5)\n",
    "model.fit(pred, y)\n",
    "predicted = model.predict_class(pred)\n",
    "model.score(predicted, y_test_proc1)\n"
   ],
   "id": "16fb34e4ace981b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def score(predicted, y):\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    correct = (predicted.flatten() == y_true)\n",
    "    return np.mean(correct)\n",
    "\n",
    "def make_cross_validation_predict_stacking(model_factories, meta_model_factory, preproc, X_set, y_set, k=5):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    y_encoded = LabelEncoder().fit_transform(y_set)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_set, y_encoded):\n",
    "        X_train_raw = X_set.iloc[train_index]\n",
    "        X_test_raw = X_set.iloc[test_index]\n",
    "        y_train_raw = y_set.iloc[train_index]\n",
    "        y_test_raw = y_set.iloc[test_index]\n",
    "\n",
    "        # preprocess\n",
    "        X_train = preproc.fit_transform(X_train_raw)\n",
    "        X_test = preproc.transform(X_test_raw)\n",
    "\n",
    "        y_train = pd.get_dummies(y_train_raw).astype(int).to_numpy()\n",
    "        y_test = pd.get_dummies(y_test_raw).astype(int).to_numpy()\n",
    "\n",
    "        base_preds_train = []\n",
    "        base_preds_test = []\n",
    "\n",
    "        for factory in model_factories:\n",
    "            model = factory()\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            pred_train = model.predict_class(X_train)\n",
    "            pred_test = model.predict_class(X_test)\n",
    "\n",
    "            pred_train = np.array([np.bincount(row).argmax() for row in pred_train]) #count most frequent classes\n",
    "            pred_test = np.array([np.bincount(row).argmax() for row in pred_test])\n",
    "\n",
    "            base_preds_train.append(pred_train.reshape(-1, 1))\n",
    "            base_preds_test.append(pred_test.reshape(-1, 1))\n",
    "\n",
    "        stacked_train = np.hstack(base_preds_train)\n",
    "        stacked_test = np.hstack(base_preds_test)\n",
    "\n",
    "\n",
    "        meta_model = meta_model_factory()\n",
    "        meta_model.fit(stacked_train, y_train)\n",
    "\n",
    "        final_pred = meta_model.predict_class(stacked_test)\n",
    "        final_pred = np.array([np.bincount(row).argmax() for row in final_pred])\n",
    "\n",
    "        fold_score = score(final_pred, y_test)\n",
    "        scores.append(fold_score)\n",
    "\n",
    "    return scores, np.mean(scores)\n",
    "model_factories = [\n",
    "    lambda: BaseLogisticRegression(n_iters=5000, lr=0.001),\n",
    "    lambda: BaseLogisticRegressionRegCombined(n_iters=4000, lr=0.001, batch_size=128, l=0.0010, alpha=0.50)\n",
    "]\n",
    "\n",
    "meta_model_factory = lambda: BaseLogisticRegression(n_iters=3000, lr=0.001)\n",
    "\n",
    "scores, mean_score = make_cross_validation_predict_stacking(\n",
    "    model_factories,\n",
    "    meta_model_factory,\n",
    "    modified_features_preprocessor,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(\"Fold scores:\", scores)\n",
    "print(\"Mean score:\", mean_score)\n"
   ],
   "id": "d8270fde664c4172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "VII. Mixture of Experts\n",
    "Mixture of experts is a method where \"supervisor\" assigns weight (in meaning of importance of particular model from experts models embedded in this method). This \"supervisor\" here is called Gating Network - this is way to assign a value of trust to each model\n"
   ],
   "id": "a3fc031738d61702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_proc1, X_test_proc1, y_train_proc1, y_test_proc1 = transform_in_pipeline(\n",
    "    modified_features_preprocessor, X_train, X_test, y_train, y_test)"
   ],
   "id": "f419c8610590cec7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class MixtureOfExperts:\n",
    "    def __init__(self, model1, model2, num_classes):\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.gating_model = RandomForestClassifier()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model1.fit(X_train, y_train)\n",
    "        self.model2.fit(X_train, y_train)\n",
    "\n",
    "        self.model1.predict_class(X_train)\n",
    "        proba1 = self.model1.probabilities\n",
    "        self.model2.predict_class(X_train)\n",
    "        proba2 = self.model1.probabilities\n",
    "\n",
    "        if len(y_train.shape) > 1:\n",
    "            y_true = np.argmax(y_train, axis=1)\n",
    "        else:\n",
    "            y_true = y_train\n",
    "\n",
    "        X_gating_train = []\n",
    "        gating_labels = []\n",
    "\n",
    "        for i in range(len(X_train)):\n",
    "            pred1 = np.argmax(proba1[i])\n",
    "            pred2 = np.argmax(proba2[i])\n",
    "\n",
    "            acc1 = int(pred1 == y_true[i])\n",
    "            acc2 = int(pred2 == y_true[i])\n",
    "\n",
    "            if acc1 > acc2:\n",
    "                label = 0\n",
    "            elif acc2 > acc1:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = i % 2  #random\n",
    "\n",
    "            features = np.concatenate([\n",
    "                X_train[i].flatten(),\n",
    "                proba1[i],\n",
    "                proba2[i],\n",
    "                np.abs(proba1[i] - proba2[i])\n",
    "            ])\n",
    "            X_gating_train.append(features)\n",
    "            gating_labels.append(label)\n",
    "\n",
    "        X_gating_train = np.array(X_gating_train)\n",
    "        gating_labels = np.array(gating_labels)\n",
    "\n",
    "        if len(gating_labels) == 0:\n",
    "            return\n",
    "\n",
    "        self.gating_model.fit(X_gating_train, gating_labels)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.model1.predict_class(X_test)\n",
    "        proba1 = self.model1.probabilities\n",
    "        self.model2.predict_class(X_test)\n",
    "        proba2 = self.model2.probabilities\n",
    "\n",
    "        X_gating_test = []\n",
    "        for i in range(len(X_test)):\n",
    "            features = np.concatenate([\n",
    "                X_test[i].flatten(),\n",
    "                proba1[i],\n",
    "                proba2[i],\n",
    "                np.abs(proba1[i] - proba2[i])\n",
    "            ])\n",
    "            X_gating_test.append(features)\n",
    "        X_gating_test = np.array(X_gating_test)\n",
    "\n",
    "        gating_probs = self.gating_model.predict_proba(X_gating_test)\n",
    "\n",
    "        final_preds = []\n",
    "        for i in range(len(X_test)):\n",
    "            weighted_vote = gating_probs[i][0] * proba1[i] + gating_probs[i][1] * proba2[i]\n",
    "            final_preds.append(np.argmax(weighted_vote))\n",
    "        return np.array(final_preds)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        preds = self.predict(X_test)\n",
    "        if len(y_test.shape) > 1:\n",
    "            y_true = np.argmax(y_test, axis=1)\n",
    "        else:\n",
    "            y_true = y_test\n",
    "        return np.mean(preds == y_true)\n"
   ],
   "id": "e8bee00d1c9e5980",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we train our expert models independently. Then, for each record in the training data, we determine which expert made the correct prediction. Based on this, we build a gating matrix, which learns to identify which expert is more likely to be correct given a specific input sample X\n",
    "\n",
    "During prediction, for each test record, we retrieve the class probability distributions from both experts. We then weight these probabilities using the gating model's output (i.e., its trust in each expert). Finally, we combine the weighted predictions and select the class with the highest final score as the predicted class."
   ],
   "id": "a795976e172a5c20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "m1 = BaseLogisticRegression(n_iters=7000, lr=0.001, batch_size=64)\n",
    "m2 = BaseLogisticRegressionRegCombined(n_iters=4000, lr=0.001, batch_size=128, l=0.00101, alpha=0.70)\n",
    "moe = MixtureOfExperts(m1, m2,3)\n",
    "moe.fit(X_train_proc1, y_train_proc1)\n",
    "acc = moe.score(X_test_proc1, y_test_proc1)\n",
    "print(f\"Mixture of Experts accuracy: {acc:.4f}\")\n"
   ],
   "id": "16e5e8af6eb97788",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5255b0b8fdc21b1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6234fb128a99a49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "X = df.drop([\"Target\"],axis=1)\n",
    "df[\"Target\"] = LabelEncoder().fit_transform(df[\"Target\"])\n",
    "y = df[\"Target\"]"
   ],
   "id": "3e36a699d349a647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features_modified),\n",
    "    ('cat', categorical_pipeline, categorical_features_modified)\n",
    "])\n",
    "\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Siatka hiperparametrów\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(random_forest_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Wyniki\n",
    "print( grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ],
   "id": "43ca15f9c52a667a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "26dd7bde774e7efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6914b1869f4148c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
